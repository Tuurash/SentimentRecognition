

# Resources Used 
CMU-MOSEI Dataset | Papers With Code (CMU Multimodal Opinion Sentiment and Emotion Intensity (CMU-MOSEI) is the largest dataset of sentence level sentiment analysis and emotion recognition in online videos. CMU-MOSEI contains more than 65 hours of annotated video from more than 1000 speakers and 250 topics.)
https://paperswithcode.com/dataset/cmu-mosei

[1] Andrea C. Samson, Sylvia D. Kreibig, B. Soderstrom, A. Ayanna Wad,
“Eliciting positive, negative and mixed emotional states: A film library
for affective scientists.”, Cognition and Emotion, vol. 30, no. 5, 2015,
pp. 827–856. https://doi.org/10.1080/02699931.2015.1031089
[2] Beatrice de Gelder ,”Why bodies? Twelve reasons for including bodily
expressions in affective neuroscience.”, Phil. Trans. R. Soc. B (2009)
364, 3475–3484. https://doi.org/10.1098/rstb.2009.0190
[3] D. Das, S. Bandyopadhyay : Sentence level emotion tagging.
In: 2009 3rd International Conference on Affective Computing
and Intelligent Interaction and Workshops, pp. 1–6. IEEE (2009).
https://doi.org/10.1109/acii.2009.5349598
[4] Tegar S. Utomo, R. Sarno and Suhariyanto,”Emotion Label from ANEW
dataset for Searching Best Definition from WordNet”, International Seminar on Application for Technology of Information and Communication
(2018) 249-252. https://doi.org/10.1109/isemantic.2018.8549769
[5] T. K. Landauer and S. T. Dumais, “A solution to plato’s problem: The
latent semantic analysis theory of acquisition, induction, and representation of knowledge.” Psychological review, vol. 104, no. 2, p. 211, 1997.
https://doi.org/10.1037/0033-295x.104.2.211[6] Eissa M.Alshari and A. Azman, ”Effective Method for Sentiment Lexical
Dictionary Enrichment based on Word2Vec for Sentiment Analysis”,
Fourth Int. Conf. on Information Retrieval and Knowledge Management,
2018 https://doi.org/10.1109/infrkm.2018.8464775
[7] Asghar, Muhammad Zubair, et al. “Sentence-Level Emotion Detection
Framework Using Rule-Based Classification.” Cognitive Computation,
vol. 9, no. 6, 2017, pp. 868–894., doi:10.1007/s12559-017-9503-3.
https://doi.org/10.1007/s12559-017-9503-3
[8] Samson, Andrea C., et al. “Eliciting Positive, Negative and
Mixed Emotional States: A Film Library for Affective Scientists.” Cognition and Emotion, vol. 30, no. 5, 2015, pp. 827–856.,
doi:10.1080/02699931.2015.1031089. Strapparava C., Mihalcea R.:
SemEval-2007 task 14: affective text. In: Proceedings of the Fourth
International Workshop on Semantic Evaluations (SemEval-2007), pp.
70–74 (2007) https://doi.org/10.3115/1621474.1621487
[9] [used] R. Dong, O. Peng, X. Li and X. Guan, ”CNN-SVM
with Embedded Recurrent Structure for Social Emotion Prediction,”
2018 Chinese Au- tomation Congress (CAC), 2018, pp. 3024-3029
https://doi.org/10.1109/cac.2018.8623318
[10] Strapparava, C., Mihalcea, R.: Learning to identify emotions in text.
In:Proceedings of the 2008 ACM Symposium on Applied Computing,
pp. 1556–1560 (2008). https://doi.org/10.1145/1363686.1364052
[11] Shaheen, S., El-Hajj, W., Hajj, H., Elbassuoni, S.: Emotion recognition
from text based on automatically generated rules. In: IEEE International Conference on Data Mining Workshop, pp. 383–392 (2014)
https://doi.org/10.1109/icdmw.2014.80
[12] M. S. Ozerdem and H. Polat, “Emotion recognition based on EEG
features in movie clips with channel selection,” Brain Inf., vol. 4, no.
4, pp. 241–252, 2017. https://doi.org/10.1007/s40708-017-0069-3
[13] Hongli Zhang , Alireza Jolfaei , and Mamoun Alazab, “A Face
Emotion Recognition Method Using Convolutional Neural Network
and Image Edge Computing,” IEEE ACCESS, Nov, 2019. 2949741
https://doi.org/10.1109/access.2019.2949741
[14] H. Ma and T. Celik, “FER-Net: Facial expression recognition using
densely connected convolutional network,” Electron. Lett., vol. 55, no.
4, pp. 184–186, Feb. 2019. https://doi.org/10.1049/el.2018.7871
[15] A. V. Savchenko, “Deep neural networks and maximum likelihood
search for approximate nearest neighbor in video-based image recognition,” Opt. Memory Neural Netw., vol. 26, no. 2, pp. 129–136, Apr.
2017. https://doi.org/10.3103/s1060992x17020102
[16] Salah, Albert Ali. Multimodal Behavior Analysis in the Wild
Video-based emotion recognition in the wild. , (2019), 369-386
https://doi.org/10.1016/b978-0-12-814601-9.00031-6
